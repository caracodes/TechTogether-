# -*- coding: utf-8 -*-
"""
Spyder Editor

This is a temporary script file. 
"""
import bs4
import pandas as pd 
import sklearn.metrics
import keras
import numpy as np
import spacy
import pickle
import sys


from pandas import DataFrame
df = pd.read_excel (r'final_code_df.xlsx', index_col=0) #for an earlier version of Excel, you may need to use the file extension of 'xls'
train_data = df.iloc[:20,]
dev_data = df.iloc[21:26,]
dev_data
  
#Tuning params
sent_len = 9800
lr = 0.001
width = 128 # size of the middle layer neural network 
epochs = 10
callbacks = [keras.callbacks.EarlyStopping(patience=2)]
threshold = .34 #.34 is max @0.568
model_dir = "models/model_0.538.h5"
dynamic_threshold = False

security_vars = ['targeted_advertising ', 'location ', "device_info\ndigital fingerprinting", "sharing_with_third_\nparty",'attaining_data_with_third_party ',"terms_changed_anytime"]

def train(train_data,dev_data):
    #Divide data
    # train_data = training 
    # dev_data = test data 
    train_text = train_data["privacy_policy"]
    train_labels = train_data[security_vars].values
    dev_text = dev_data["privacy_policy"]
    dev_labels = dev_data[security_vars].values
    
    #Spacy pipe initialization
    #"Hit 'em with the pipe!"
    nlp = spacy.load("en_vectors_web_lg")
    nlp.add_pipe(nlp.create_pipe('sentencizer'))
    embeddings = nlp.vocab.vectors.data
    train_docs, train_labels, train_x = postprocess(train_text,nlp,train_labels)
    dev_docs, dev_labels, dev_x = postprocess(dev_text,nlp,dev_labels)
    
    #Create keras model
    inputs = keras.Input((sent_len,))
    x = keras.layers.Embedding(embeddings.shape[0],embeddings.shape[1],
                               input_length = sent_len, trainable = False,
                               weights = [embeddings], mask_zero = True)(inputs)
    x = keras.layers.TimeDistributed(keras.layers.Dense(width))(x)
    x = keras.layers.Bidirectional(keras.layers.GRU(width))(x)
    x = keras.layers.Dense(6, activation = "sigmoid")(x)
    model = keras.Model(inputs = inputs, outputs = x)
    model.compile(keras.optimizers.Adam(lr = lr),loss = "mse",metrics=['accuracy'])
    
    #Train model
    model.fit(train_x, train_labels, validation_data = (dev_x, dev_labels),
              epochs = epochs, callbacks = callbacks)
    
    model.save("models/model.h5")

def postprocess(text, nlp, labels=None):
    docs = list(nlp.pipe(text))
    x = get_features(docs, sent_len)
    if labels is None:
        return docs, x
    else:
        return docs, labels, x

#Borrowed from Spacy tutorial
def get_features(docs, max_length):  
    docs = list(docs)
    Xs = np.zeros((len(docs), max_length), dtype='int32')
    for i, doc in enumerate(docs):
        j = 0
        for token in doc:
            vector_id = token.vocab.vectors.find(key=token.orth)
            if vector_id >= 0:
                Xs[i, j] = vector_id
            else:
                Xs[i, j] = 0
            j += 1
            if j >= max_length:
                break
    return Xs


train(train_data,dev_data)
    
